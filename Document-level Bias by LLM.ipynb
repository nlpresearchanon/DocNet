{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4df8b31-1845-4c41-9afe-e16be1468897",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pip install transformers accelerate langchain langchain-core langchain-openai bitsandbytes\n",
    "'''\n",
    "import pandas as pd, numpy as np, os, re\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444fe1df-d74f-4e28-8c93-b915d4ae69ce",
   "metadata": {},
   "source": [
    "# Read in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c27cc7e-d45f-4bf8-a649-836ecc2acc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV files into DataFrames\n",
    "\n",
    "df = pd.read_pickle(\"processeddataname.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7870324-111d-408e-b7a1-0ce5dda35a91",
   "metadata": {},
   "source": [
    "# Create LLMs\n",
    "- stand up both an OpenAI and a local models\n",
    "- test to make sure they work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf8aae-55dc-4bea-8b41-ec5769510733",
   "metadata": {},
   "source": [
    "### OpenAI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf430a-c237-4917-a483-5a4d7d90e0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the key file path\n",
    "\n",
    "file_path = \"\"\n",
    "\n",
    "# Read the api key from the file\n",
    "with open(file_path, 'r') as file:\n",
    "    api_key = file.read().strip()\n",
    "\n",
    "openai_llm = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943eef04-441c-41a6-b71c-664491b4a4db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "openai_llm.invoke(f'''Please classify the following news article by its political bias. Please only classify the article as \"far right\", \"right\", \"center right\", \"center\", \"center left\", \"left\", or \"far left\", and return no other text.\n",
    "article: {df[\"text\"][1]}\n",
    "bias: ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b6d657-6d08-4ad4-a7c3-d6b6aac66165",
   "metadata": {},
   "source": [
    "### Local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267cbd09-9964-44d9-9500-cfa32b81e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "# read in huggingface token\n",
    "with open('.root/hf.txt', 'r') as file:  \n",
    "    token = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf35e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model, token=token)\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit = True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model, \n",
    "    # quantization_config=quantization_config, \n",
    "    token=token, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad05af1e-21b0-4ef7-8d9b-1b9790f81552",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model, token=token)\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit = True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model, \n",
    "    # quantization_config=quantization_config, \n",
    "    token=token, device_map=\"auto\")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text = False,\n",
    "    max_new_tokens=10,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a0db1b-f827-495d-ab04-e5b6e72252c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm.invoke(f'''Please classify the following news article by its political bias. Please only classify the article as \"far right\", \"right\", \"center right\", \"center\", \"center left\", \"left\", \"far left\", adn return no other text.\n",
    "article: {df[\"text\"][1]}\n",
    "bias: ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9280d0d1-28e5-45ec-8164-a92e79260a43",
   "metadata": {},
   "source": [
    "# Create Prompts and Chains\n",
    "- one with full spectrum of bias labels\n",
    "- one with \"left\", \"right\", and \"center\" only\n",
    "- one with \"biased\" and \"not biased\" only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483fb085-4c6d-44bd-8133-c2153319f9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_template = '''Please classify the following news article by its political bias. Please only classify the article as \"far right\", \"right\", \"center right\", \"center\", \"center left\", \"left\", or \"far left\", and return no other text.\n",
    "title: {title}\n",
    "article: {article}\n",
    "bias: '''\n",
    "\n",
    "base_prompt = PromptTemplate(\n",
    "    input_variables = ['title','article'],\n",
    "    template = base_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1128298-05af-4557-8eba-7356aec8fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_chain_openai = base_prompt | openai_llm | StrOutputParser()\n",
    "#base_chain_local =  base_prompt | local_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37016f72-65d1-4413-9460-1250b5b4c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_template = '''Please classify the following news article by its political bias. Please only classify the article as \"right\", \"center\", or \"left\" and return no other text.\n",
    "title: {title}\n",
    "article: {article}\n",
    "bias: '''\n",
    "\n",
    "reduced_prompt = PromptTemplate(\n",
    "    input_variables = ['title','article'],\n",
    "    template = reduced_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e0dde5-4457-43ea-831c-be39d4af6a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_chain_openai = reduced_prompt | openai_llm | StrOutputParser()\n",
    "#reduced_chain_local =  reduced_prompt | local_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f70208-6656-4f86-845b-f9cb605293bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_only_template = '''Please classify the following news article as to whether it is politically biased or unbiased. Only return the bias classification as \"biased\" or \"unbiased\" and no other text.\n",
    "title: {title}\n",
    "article: {article}\n",
    "bias: '''\n",
    "\n",
    "bias_only_prompt = PromptTemplate(\n",
    "    input_variables = ['title','article'],\n",
    "    template = bias_only_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccac3cc-2961-4e07-92d4-8fe5cbd5d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_only_chain_openai = bias_only_prompt | openai_llm | StrOutputParser()\n",
    "#bias_only_chain_local =  bias_only_prompt | local_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2d2004-8de5-4d51-b4d0-13a23e3d417c",
   "metadata": {},
   "source": [
    "# Run on the whole dataset and classify the bias of the articles\n",
    "\n",
    "- define some helper functions and dicts to help with the formatting and cleaning the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20714be-b105-4cbf-9200-a7b45a573476",
   "metadata": {},
   "outputs": [],
   "source": [
    "recode_mapping = {\n",
    "    'center': 'CENTER',\n",
    "    'Center' :\"CENTER\",\n",
    "    'center左': \"CENTER\",\n",
    "    'center右': \"CENTER\",\n",
    "    'N/A': \"CENTER\",\n",
    "    'center left': \"LEFT-CENTER\",\n",
    "    'center-left': \"LEFT-CENTER\",\n",
    "    'center;left': \"LEFT-CENTER\",\n",
    "    'center\\tleft': \"LEFT-CENTER\",\n",
    "    'centerleft': \"LEFT-CENTER\",\n",
    "    'center right': \"RIGHT-CENTER\",\n",
    "    'center\\tright': \"RIGHT-CENTER\",\n",
    "    'centerright': \"RIGHT-CENTER\",\n",
    "    'far left': \"FAR LEFT\", \n",
    "    'far right': \"FAR RIGHT\",\n",
    "    'right': \"RIGHT\",\n",
    "    'left': \"LEFT\",\n",
    "    'Left': \"LEFT\",\n",
    "    \"Right\":\"RIGHT\",\n",
    "    'center  left':\"LEFT-CENTER\", \n",
    "    'Center Right':\"RIGHT-CENTER\", \n",
    "    'far  left':\"FAR LEFT\",\n",
    "    'center  right':\"RIGHT-CENTER\",\n",
    "    'Center right':\"RIGHT-CENTER\",\n",
    "    'Center Left':\"LEFT-CENTER\",\n",
    "    'CenterLeft':\"LEFT-CENTER\",\n",
    "    'far  right':\"FAR RIGHT\",\n",
    "    'centerright':\"RIGHT-CENTER\", \n",
    "    'unbiased':\"CENTER\", \n",
    "    'biased':\"CENTER\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb2a15-73e4-4ab5-8391-7d32a8423320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bias_text(text_list):\n",
    "    # Regular expressions to match bias labels\n",
    "    patterns = {\n",
    "        'far right': r'\\b(far\\s*right)\\b',\n",
    "        'center right': r'\\b(center\\s*right)\\b',\n",
    "        'center left': r'\\b(center\\s*left)\\b',\n",
    "        'far left': r'\\b(far\\s*left)\\b',\n",
    "        'right': r'\\b(right)\\b',\n",
    "        'center': r'\\b(center)\\b',\n",
    "        'left': r'\\b(left)\\b',\n",
    "        'unbiased': r'\\b(unbiased)\\b',\n",
    "        'biased': r'\\b(biased)\\b'\n",
    "    }\n",
    "    \n",
    "    # Initialize list to store extracted text for each position in text_list\n",
    "    extracted_text_list = []\n",
    "    \n",
    "    # Iterate through the text list and extract bias labels for each position\n",
    "    for text in text_list:\n",
    "        extracted_text = None\n",
    "        for label, pattern in patterns.items():\n",
    "            # Find the first match of the pattern in the text\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                # Set the extracted text to the matched text\n",
    "                extracted_text = match.group(0)\n",
    "                break  # Exit the loop after finding the first match\n",
    "        # If no match is found, classify as 'center'\n",
    "        if extracted_text is None:\n",
    "            extracted_text = 'center'\n",
    "        # Append the extracted text to the list\n",
    "        extracted_text_list.append(extracted_text)\n",
    "                \n",
    "    return extracted_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f62729-6733-46c7-88e9-822975d96781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-3 Turbo default: 76000\n",
    "\n",
    "def truncate_text(text, max_length=76000):\n",
    "    if len(text) > max_length:\n",
    "        return text[:max_length]\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f060bb-b1dd-491b-ae35-52c8402d65dc",
   "metadata": {},
   "source": [
    "# OpenAI run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20367e5f-c37e-4e6d-a7fc-76df72763fdc",
   "metadata": {},
   "source": [
    "Full set of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3b8b5-703d-4e53-aadc-78cd747e0a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    article = truncate_text(row[\"text\"])\n",
    "    title = row[\"title\"]\n",
    "    try:\n",
    "        results.append(base_chain_openai.invoke({\"article\":article, \"title\":title}))\n",
    "    except Exception as e:\n",
    "        print(\"Caught error:\", e)\n",
    "        print(\"Waiting for 3 seconds before retrying...\")\n",
    "        sleep(3)  # Wait for 3 seconds before retrying\n",
    "        try:\n",
    "            results.append(base_chain_openai.invoke({\"article\":article, \"title\":title}))\n",
    "        except Exception as e:\n",
    "            print(\"Caught error again. Skipping this row.\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b766c743-a9c9-4a8e-a672-560f570c3b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99934a4b-2243-4513-b554-c21b1175f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article_bias_gpt_base_prompt'] = results\n",
    "df['article_bias_gpt_base_prompt'] = df['article_bias_gpt_base_prompt'].map(recode_mapping).fillna(df['article_bias_gpt_base_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64454a7-0d80-4049-a4ce-dbdec1891437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out interim results\n",
    "df.to_csv(\"interim_zero_shot_llm_labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f6eec6-b3e3-4d87-a731-3b1126b92c44",
   "metadata": {},
   "source": [
    "Reduced set of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edbd95e-9ad2-4fda-8445-2f7ecfa2bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    article = truncate_text(row[\"text\"])\n",
    "    title = row[\"title\"]\n",
    "    try:\n",
    "        results.append(reduced_chain_openai.invoke({\"article\":article, \"title\":title}))\n",
    "    except Exception as e:\n",
    "        print(\"Caught error:\", e)\n",
    "        print(\"Waiting for 10 seconds before retrying...\")\n",
    "        sleep(10)  # Wait for n seconds before retrying\n",
    "        try:\n",
    "            results.append(reduced_chain_openai.invoke({\"article\":article, \"title\":title}))\n",
    "        except Exception as e:\n",
    "            print(\"Caught error again. Skipping this row.\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af8b72-36e4-4821-9a5b-3722fd7d32e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5401fd-41e6-4f43-b0f4-726863a8ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article_bias_gpt_reduced_prompt'] = results\n",
    "df['article_bias_gpt_reduced_prompt'] = df['article_bias_gpt_reduced_prompt'].map(recode_mapping).fillna(df['article_bias_gpt_reduced_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e83c8-6dd4-4ade-80b3-b79d81b9d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out interim results\n",
    "df.to_csv(\"interim_zero_shot_llm_labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5663b3c5-abe3-41cc-a7cd-804fec91e36d",
   "metadata": {},
   "source": [
    "Bias only labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86834edf-1430-4b06-917d-b17227e3492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    article = truncate_text(row[\"text\"])\n",
    "    title = row[\"title\"]\n",
    "    try:\n",
    "        results.append(bias_only_chain_openai.invoke({\"article\":article, \"title\":title}))\n",
    "    except Exception as e:\n",
    "        print(\"Caught error:\", e)\n",
    "        print(\"Waiting for 3 seconds before retrying...\")\n",
    "        sleep(3)  # Wait for 3 seconds before retrying\n",
    "        try:\n",
    "            results.append(bias_only_chain_openai.invoke({\"article\":article, \"title\":title}))\n",
    "        except Exception as e:\n",
    "            print(\"Caught error again. Skipping this row.\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f84ebb-7717-4d5a-a3dd-e736e7c7a7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35bed9d-41a1-46b6-9839-bf89badb6883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article_bias_gpt_bias_only_prompt'] = results\n",
    "df['article_bias_gpt_bias_only_prompt'] = df['article_bias_gpt_bias_only_prompt'].map({'Unbiased':'unbiased'}).fillna(df['article_bias_gpt_bias_only_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bcd20b-ff2b-4d45-9fc5-5468a4f9fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out interim results\n",
    "df.to_csv(\"interim_zero_shot_llm_labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd760f18-55c8-404f-a874-6c545e069c74",
   "metadata": {},
   "source": [
    "# Local Model Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff62894d-77ce-44b7-b56c-7b5de635f92d",
   "metadata": {},
   "source": [
    "full set of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d17739-d844-4a6e-947d-4ad17fcc953a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    article = truncate_text(row[\"text\"], max_length=30000)\n",
    "    title = row[\"title\"]\n",
    "    results.append(base_chain_local.invoke({\"article\":article, \"title\":title}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f405f-24e2-4879-adc1-c9c04a835621",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = extract_bias_text(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4b6f5b-183c-413e-bd26-aea4e607819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7760913-4439-4c66-bf58-d436ad317451",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article_bias_llama_base_prompt'] = results\n",
    "df['article_bias_llama_base_prompt'] = df['article_bias_llama_base_prompt'].map(recode_mapping).fillna(df['article_bias_llama_base_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69782456-dae9-496b-9d58-ec58acbc298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out interim results\n",
    "df.to_csv(\"interim_zero_shot_llm_labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6e075e-c2ed-4741-8d0d-4f759b20625f",
   "metadata": {},
   "source": [
    "reduced set of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d0eb29-59a6-4be3-bace-6b886bd7ac24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    article = truncate_text(row[\"text\"], max_length=30000)\n",
    "    title = row[\"title\"]\n",
    "    results.append(reduced_chain_local.invoke({\"article\":article, \"title\":title}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0835e2c7-0bb9-4210-a1fd-cd2f8571a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = extract_bias_text(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45937721-ab56-4b5c-b113-bee90f9b59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b401e0f-094b-4a19-b64f-5d293b520f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article_bias_llama_reduced_prompt'] = results\n",
    "df['article_bias_llama_reduced_prompt'] = df['article_bias_llama_reduced_prompt'].map(recode_mapping).fillna(df['article_bias_llama_reduced_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ae3da7-9518-4ad3-9138-af6c37c26be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out interim results\n",
    "df.to_csv(\"interim_zero_shot_llm_labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549ee837-3bd0-416d-829d-9ebe43d478a2",
   "metadata": {},
   "source": [
    "Bias only labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d63c498-b787-4053-8444-725fec8ae961",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    article = truncate_text(row[\"text\"], max_length=30000)\n",
    "    title = row[\"title\"]\n",
    "    results.append(bias_only_chain_local.invoke({\"article\":article, \"title\":title}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad09de9-6bcf-4056-8d7a-35218e2a93cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = extract_bias_text(results)\n",
    "for i in range(len(results)):\n",
    "    if results[i] == 'right':\n",
    "        results[i] = 'biased'\n",
    "    elif results[i] == 'center':\n",
    "        results[i] = 'unbiased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc91252-1330-4624-85a9-e1699e1af557",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6f2949-ebcd-413c-b1a1-bf93fd0bd2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article_bias_llama_bias_only_prompt'] = results\n",
    "df['article_bias_llama_bias_only_prompt'] = df['article_bias_llama_bias_only_prompt'].map(\n",
    "    {\"Left\":\"biased\", \"Biased\":\"biased\", \"Unbiased\":\"unbiased\", \"left\":\"unbiased\"}\n",
    ").fillna(df['article_bias_llama_bias_only_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d07e59a-091b-443f-8308-5f338ebd86a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df['article_bias_llama_bias_only_prompt'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db1958e-7450-4571-bc53-51e86cf1c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out interim results\n",
    "df.to_csv(\"interim_zero_shot_llm_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878ef73c-25e9-431e-b8cd-c2f02b12fe1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
